---
title: "Projet_Statistiques"
author: "Mouhamadou_Mansour_BA"
date: "2024-11-22"
output: pdf_document
---

## **MEMBRES DU GROUPE :**

-   Mouhamadou Mansour BA (IIA)
-   Mame Peuya DIA (IIA)
-   Fatou FALL (SEM)
-   Khoudia Bintou FALL (CAA)

**PLAN**

***Introduction***

***Exercice 1 : Simulation de Lois***

-   1.1 Simulation de la loi binomiale B(30, 0.5)
    -   G√©n√©ration d'un √©chantillon de taille 10 000
    -   Trac√© de l‚Äôhistogramme de l‚Äô√©chantillon
    -   Interpr√©tation de l'histogramme
-   1.2 Simulation de la loi normale N(3, 0.9)
    -   G√©n√©ration d'un √©chantillon de taille 10 000
    -   Trac√© de la fonction de densit√© de l‚Äô√©chantillon
    -   Interpr√©tation de l'histogramme
-   1.3 Simulation de la loi du X¬≤ avec 20 degr√©s de libert√©
    -   G√©n√©ration d'un √©chantillon de taille 10 000
    -   Trac√© de la fonction de densit√© de l‚Äô√©chantillon
    -   Interpr√©tation de l'histogramme

***Exercice 2 : M√©thode de Monte Carlo***

-   2.1 Estimation de l‚Äôint√©grale I2
    -   Utilisation de la m√©thode de Monte Carlo avec n= 10000
-   2.2 Graphique d‚Äô√©volution de l‚Äôestimation
    -   Trac√© de la convergence de l‚Äôestimation en fonction de n
    -   V√©rification de la coh√©rence avec la valeur th√©orique I2 = Pi/4
    -   Interpr√©tation du graphe

***Exercice 3 : R√©gression Lin√©aire***

-   3.1 Pr√©paration des donn√©es
    -   Enregistrement des couples d‚Äôobservations (xi,yi) dans un format adapt√© pour Python
-   3.2 Analyse de la relation entre yi et xi
    -   Trac√© des points (xi,yi)
    -   Observation d‚Äôune possible liaison lin√©aire
-   3.3 Calcul de la droite des moindres carr√©s
    -   Estimation des coefficients de la droite de r√©gression
-   3.4 Calcul des valeurs estim√©es de yi
    -   Calcul des ordonn√©es des yi estim√©s pour chaque xi
-   3.5 Trac√© de la droite de r√©gression
    -   Ajout de la droite sur le graphique de dispersion
-   3.6 Estimation deùëåpour xi=21
    -   Calcul de la valeur estim√©e deùëå
-   3.7 Calcul de l‚Äô√©cart
    -   Calcul de l‚Äô√©cart entre la valeur observ√©e et la valeur estim√©e pour xi=21
-   3.8 V√©rification du passage par le point moyen t (x¬Ø, y¬Ø)
    -   Discussion sur la g√©n√©ralisation du passage par le point moyen pour toute droite de r√©gression

***Exercice 4 : Donn√©es COVID-19 au S√©n√©gal***

-   4.1 Lecture et nettoyage des donn√©es

    -   Lecture du fichier regions_cas.csv
    -   Nettoyage des noms de r√©gions et conversion de la variable date en type datetime

-   4.2 Cr√©ation du DataFrame avec date, region, maladesparegion

    -   Fonction pour regrouper les cas par r√©gion et par date

-   4.3 Estimation du param√®tre Œª pour la loi de Poisson

-   Calcul du param√®tre de la distribution de Poisson

-   4.4 Test de la loi de Poisson

    -   Test statistique pour v√©rifier si maladesparegion suit une loi de Poisson

-   4.5 Estimation des param√®tres r et p pour la loi binomiale n√©gative

    -   Calcul des param√®tres de la distribution binomiale n√©gative

-   4.6 Visualisation des donn√©es par carte

    -   Fonction CarteRegions(madate) pour afficher une carte choropl√®the des r√©gions du S√©n√©gal avec les cas de COVID-19

***Conclusion***

***INTRODUCTION :***

*Ce document pr√©sente les solutions aux exercices de statistiques math√©matiques pour le Master 1 en Sciences des donn√©es √† l‚ÄôUniversit√© Iba Der THIAM de Thi√®s. Ce projet comprend des simulations de lois de probabilit√©, une estimation par la m√©thode de Monte Carlo, une analyse de r√©gression lin√©aire, et une √©tude de donn√©es COVID-19 au S√©n√©gal.*

# ***Exercice 1 : Simulation de lois***

# *1.1 Simulation de la loi binomiale B(30, 0.5)*

*Dans cette premi√®re √©tape, nous simulons un √©chantillon de taille 10000 suivant une loi binomiale avec 30 essais et une probabilit√© de succ√®s de 0,5.*

*- G√©n√©ration de l'√©chantillon*

*L'objectif est de simuler un √©chantillon de taille 10 000 provenant d'une distribution binomiale. La loi binomiale B(n,p) d√©crit le nombre de succ√®s dans n essais ind√©pendants, chacun ayant une probabilit√© de succ√®s p Dans cet exercice, nous utilisons n=30 (le nombre d'essais) et p=0.5 (la probabilit√© de succ√®s dans chaque essai).La fonction `rbinom` de R permet de g√©n√©rer cet √©chantillon.*

```{r}
# Simulation d'un √©chantillon de taille 10000 suivant une loi binomiale B(30, 0.5)
sample_binomial <- rbinom(10000, size = 30, prob = 0.5)
```

*- Trac√© de l‚Äôhistogramme de l‚Äô√©chantillon*

*Une fois l'√©chantillon g√©n√©r√©, nous tra√ßons un histogramme pour visualiser la distribution des donn√©es. L'histogramme est un graphique qui montre la r√©partition des valeurs observ√©es dans l'√©chantillon.Chaque barre de l'histogramme repr√©sente le nombre d'observations qui tombent dans un intervalle donn√©.*

```{r}
# Trac√© de l'histogramme de l'√©chantillon
hist(sample_binomial, main = "Histogramme de l'√©chantillon Binomial B(30, 0.5)", 
     xlab = "Valeurs", ylab = "Fr√©quence", col = "skyblue", border = "white")
```

*Dans cet histogramme, l'axe des abscisses repr√©sente les diff√©rentes valeurs possibles du nombre de succ√®s dans les 30 essais (allant de 0 √† 30), tandis que l'axe des ordonn√©es repr√©sente la fr√©quence (ou le nombre d'occurrences) de chaque valeur dans l'√©chantillon.*

*- Interpr√©tation de l'histogramme*

*L'histogramme de la loi binomiale devrait pr√©senter une forme en cloche, sym√©trique autour de la moyenne (15 dans ce cas), repr√©sentant le nombre attendu de succ√®s. √âtant donn√© 30 essais et une probabilit√© de succ√®s de 0.5, la majorit√© des √©chantillons devraient se concentrer autour de cette valeur de 15. Les valeurs extr√™mes, proches de 0 ou de 30, seront moins fr√©quentes, ce qui est caract√©ristique d'une distribution binomiale.*

# *1.2 Simulation de la loi normale N(3, 0.9)*

*Nous simulons un √©chantillon de taille 10 000 suivant une loi normale avec une moyenne de 3 et un √©cart-type de 0,9, puis tra√ßons la fonction de densit√© de l'√©chantillon.*

*- G√©n√©ration de l'√©chantillon*

*Nous g√©n√©rons un √©chantillon de taille 10 000 suivant la loi normale N(3, 0.9). La fonction `rnorm` de R permet de g√©n√©rer cet √©chantillon.*

```{r}
# Simulation d'un √©chantillon de taille 10000 suivant une loi normale N(3, 0.9)
sample_normal <- rnorm(10000, mean = 3, sd = 0.9)
```

*- Trac√© de la fonction de densit√© de l‚Äô√©chantillon*

*Une fois l'√©chantillon g√©n√©r√©, nous tra√ßons la fonction de densit√© qui nous permettra de visualiser la r√©partition des valeurs dans l'√©chantillon, nous ajoutons √©galement une ligne pour indiquer l'intervalle contenant 0.*

```{r}
# Trac√© de la densit√© de l'√©chantillon
plot(density(sample_normal), main = "Densit√© de l'√©chantillon Normal N(3, 0.9)", 
     xlab = "Valeurs", ylab = "Densit√©", col = "purple")
abline(v = 0, col = "red", lty = 2) # Ajout d'une ligne pour l'intervalle contenant 0
```

*- Interpr√©tation de l'histogramme*

\*Le graphique de densit√© montre la distribution de l'√©chantillon simul√©. La ligne rouge repr√©sente un intervalle contenant 0. Comme la loi normale est sym√©trique, on s'attend √† ce que la majorit√© des valeurs se situent autour de la moyenne 3, avec une dispersion d√©finie par l'√©cart-type de 0.9.\*\*

# *1.3 Simulation de la loi du X¬≤ avec 20 degr√©s de libert√©*

*Tracer la fonction de densit√© de l‚Äô√©chantillon obtenu. Choisir un intervalle contenant 0 pour domaine de repr√©sentation.*

*Enfin, nous simulons un chantillon de taille 10 000 suivant une loi du chi-carr√© avec 20 degr√©s de libert√© et tra√ßons la fonction de densit√© de l'√©chantillon.*

*- G√©n√©ration de l'√©chantillon*

*Nous g√©n√©rons un √©chantillon de taille 10 000 suivant la loi du chi-carr√© avec 20 degr√©s de libert√©. La fonction rchisq permet de g√©n√©rer cet √©chantillon.*

```{r}
# Simulation d'un √©chantillon de taille 10000 suivant une loi du œá¬≤ avec 20 degr√©s de libert√©
sample_chi2 <- rchisq(10000, df = 20)

```

*- Trac√© de la fonction de densit√© de l‚Äô√©chantillon*

*Nous tra√ßons ensuite la fonction de densit√© de l'√©chantillon pour observer la r√©partition des valeurs. Comme la loi du chi-carr√© est asym√©trique et prend uniquement des valeurs positives, l'intervalle contenant 0 sera visible sur le graphique.*

```{r}
# Trac\'{e}de la densit√© de l'\'{e}chantillon
plot(density(sample_chi2), main = " Densit√© de l'√©chantillon", 
     xlab = "Valeurs", ylab = "Densit√©", col = "darkgreen")
abline(v = 0, col = "red", lty = 2) # Ligne pour l'intervalle contenant 0
```

*- Interpr√©tation de l'histogramme*

*Le graphique montre que la distribution du chi-carr√© est fortement asym√©trique, avec une forte concentration de valeurs pr√®s de 0 et une longue tra√Æne du c√¥t√© des valeurs plus √©lev√©es. La ligne rouge indique l'intervalle contenant 0, ce qui est pertinent car la loi du chi-carr√© n'a pas de valeurs n√©gatives.*

# ***Exercice 2 : M√©thode de Monte Carlo***

# *2.1 Estimation de l‚Äôint√©grale I2*

*- Utilisation de la m√©thode de Monte Carlo avec n= 10000*

*Nous estimons l‚Äôint√©grale I2 √† l‚Äôaide de la m√©thode de `Monte Carlo`. Cette m√©thode consiste √† g√©n√©rer al√©atoirement des points dans l‚Äôintervalle [0,1] et √† calculer la moyenne des valeurs de la fonction f(x) √©valu√©e en ces points. Avec n = 10 000 simulations, l‚Äôestimation obtenue sera compar√©e √† la valeur th√©orique Pi/4.*

```{r}
# Nombre de simulations
n <- 10000

# Simulation de points uniform√©ment distribu√©s sur [0, 1]
x <- runif(n)

# Fonction √† int√©grer : sqrt(1 - x^2)
f_x <- sqrt(1 - x^2)

# Estimation de l'int√©grale par la m√©thode de Monte Carlo
I2_estimation <- mean(f_x)

# Affichage de l'estimation
cat("Estimation de I2 par la m√©thode de Monte Carlo avec n =", n, ":", I2_estimation, "\n")

# Valeur th√©orique de I2
I2_theorique <- pi / 4
cat("Valeur th√©orique de I2 :", I2_theorique, "\n")
```

# *2.2 Graphique d‚Äô√©volution de l‚Äôestimation*

*- Trac√© de la convergence de l‚Äôestimation en fonction de*

*- V√©rification de la coh√©rence avec la valeur th√©orique I2 = Pi/4*

*Pour cette partie, nous visualisons comment l'estimation de I2, obtenue par `la m√©thode de Monte Carlo`, √©volue √† mesure que le nombre de simulations augmente. L'objectif est de v√©rifier la convergence de cette estimation vers la valeur th√©orique I2 = Pi/4.*

*Le graphique montre la progression de l'estimation cumul√©e apr√®s chaque simulation. Une ligne horizontale repr√©sentant la valeur th√©orique Pi/4 est ajout√©e comme r√©f√©rence visuelle pour comparer les estimations successives. Cette approche permet de v√©rifier la coh√©rence de la m√©thode utilis√©e et d'observer comment la pr√©cision s'am√©liore avec un plus grand nombre de simulations.*

```{r}
# Visualisation de l'√©volution de l'estimation avec n croissant
estimation_progression <- cumsum(f_x) / (1:n)
plot(1:n, estimation_progression, type = "l", col = "blue", 
     xlab = "Nombre de simulations", ylab = "Estimation de I2", 
     main = "√âvolution de l'estimation de I2 avec Monte Carlo")
abline(h = I2_theorique, col = "red", lty = 2) # Valeur th√©orique en rouge

# Ajout d'une l√©gende
legend("bottomright", legend = c("Estimation cumul√©e", "Valeur th√©orique I2 = œÄ/4"),
       col = c("blue", "red"), lty = c(1, 2), bty = "n")
```

*- Interpr√©tation du graphe*

*Le graphique montre l'√©volution de l'estimation de I2 en fonction du nombre de simulations n. La courbe bleue correspond √† l'estimation cumulative de I2, tandis que la ligne rouge horizontale repr√©sente la valeur th√©orique I2 = Pi/4.*

*On observe que l‚Äôestimation devient de plus en plus stable √† mesure que n augmente, convergeant vers la valeur th√©orique. Cette stabilit√© indique la validit√© de la m√©thode de Monte Carlo pour estimer des int√©grales. Pour n = 10 000, les √©carts entre les estimations successives et la valeur th√©orique deviennent n√©gligeables, d√©montrant que la pr√©cision s‚Äôam√©liore avec un plus grand nombre de simulations.*

# ***Exercice 3 : R√©gression Lin√©aire***

# *3.1 Pr√©paration des donn√©es*

*Enregistrement des couples d‚Äôobservations (xi,yi) dans un format adapt√© pour Python.*

***- Importons d'abord les biblioth√®ques n√©cessaires :***

```{python}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
```

***- Enregistrer les donn√©es :***

```{r}
# Cr√©er un data.frame pour regrouper les donn√©es
donnees <- data.frame(x = c(18, 7, 14, 31, 21, 5, 11, 16, 26, 29),
                      y = c(55, 17, 36, 85, 62, 18, 33, 41, 63, 87))

# Exporter les donn√©es au format CSV
write.csv(donnees, "donnees.csv", row.names = FALSE)

cat("Les donn√©es ont √©t√© enregistr√©es dans le fichier 'donnees.csv'.\n")
```

***- Affichage du fichier donnees.csv***

```{python}
import pandas as pd
donnees = pd.read_csv("donnees.csv")
print(donnees)
```

*Les vecteurs x et y contiennent les couples d'observations. Cela correspond √† la pr√©paration des donn√©es pour l'analyse de r√©gression lin√©aire.*

# *3.2 Analyse de la relation entre yi et xi*

*- Trac√© des points (xi,yi)*

*- Observation d‚Äôune possible liaison lin√©aire*

```{python}
# Donn√©es (x et y)
x = [18, 7, 14, 31, 21, 5, 11, 16, 26, 29]
y = [55, 17, 36, 85, 62, 18, 33, 41, 63, 87]

# Tracer un graphique de dispersion
plt.scatter(x, y, color='blue')

# Ajouter un titre et des labels
plt.title('Graphique de dispersion de y en fonction de x')
plt.xlabel('x')
plt.ylabel('y')

# Afficher le graphique
plt.show()

```

*Ce graphique permet de visualiser les points et d‚Äôobserver une √©ventuelle relation lin√©aire entre x et y.*

# *3.3 Calcul de la droite des moindres carr√©s*

*- Estimation des coefficients de la droite de r√©gression*

```{python}
# Donn√©es (x et y)
x = np.array([18, 7, 14, 31, 21, 5, 11, 16, 26, 29]).reshape(-1, 1)
y = np.array([55, 17, 36, 85, 62, 18, 33, 41, 63, 87])

# Ajustement d'une droite de r√©gression lin√©aire
model = LinearRegression()
model.fit(x, y)

# Estimation des coefficients (pente et intercept)
slope = model.coef_[0]
intercept = model.intercept_

# Afficher les coefficients
print("Coefficients de la droite des moindres carr√©s :")
print(f"Pente (slope) : {slope}")
print(f"Ordonn√©e √† l'origine (intercept) : {intercept}")
```

*Le mod√®le ajuste la droite des moindres carr√©s. Les coefficients de r√©gression sont correctement extraits et affich√©s.*

# *3.4 Calcul des valeurs estim√©es de yi*

*- Calcul des ordonn√©es des yi estim√©s pour chaque xi*

```{python}
# Calculer les valeurs estim√©es de y
y_estime = model.predict(x)

# Afficher les ordonn√©es estim√©es pour chaque x_i
print("Ordonn√©es estim√©es pour chaque xi :")
print(y_estime)
```

*Cette √©tape calcule les yi estim√©s pour chaque xi. Ces valeurs sont essentielles pour tracer la droite et √©valuer la qualit√© du mod√®le.*

# *3.5 Trac√© de la droite de r√©gression*

*- Ajout de la droite sur le graphique de dispersion*

```{python}
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression

# Donn√©es (x et y)
x = np.array([18, 7, 14, 31, 21, 5, 11, 16, 26, 29]).reshape(-1, 1)
y = np.array([55, 17, 36, 85, 62, 18, 33, 41, 63, 87])

# Ajuster un mod√®le de r√©gression lin√©aire
model = LinearRegression()
model.fit(x, y)

# Calculer les valeurs estim√©es de y (droite de r√©gression)
y_estime = model.predict(x)

# Tracer le graphique de dispersion
plt.scatter(x, y, color='blue', label='Donn√©es observ√©es')

# Ajouter la droite de r√©gression
plt.plot(x, y_estime, color='red', linewidth=2, label='Droite de r√©gression')

# Ajouter un titre et des labels
plt.title('Graphique de dispersion avec droite de r√©gression')
plt.xlabel('Variable X')
plt.ylabel('Variable Y')

# Ajouter une l√©gende
plt.legend()

# Afficher le graphique
plt.show()

```

*La droite de r√©gression est correctement ajout√©e au graphique de dispersion pour visualiser l‚Äôajustement.*

# *3.6 Estimation de ùëå pour xi=21*

*- Calcul de la valeur estim√©e de*

```{python}
# Calculer la valeur estim√©e de y pour xi = 21
x_new = 21
y_estime_21 = slope * x_new + intercept
print(f"Estimation de Y pour xi = 21 : {y_estime_21}")

```

*Cette section calcule Y pour xi = 21 √† partir du mod√®le ajust√©. C‚Äôest une application classique de la pr√©diction avec un mod√®le lin√©aire.*

# *3.7 Calcul de l‚Äô√©cart*

*- Calcul de l‚Äô√©cart entre la valeur observ√©e et la valeur estim√©e pour xi = 21*

```{python}
# Calculer l'√©cart entre la valeur observ√©e et la valeur estim√©e pour x = 21
y_observe_21 = donnees.loc[donnees['x'] == 21, 'y'].values[0]
ecart = y_observe_21 - y_estime_21
print(f"√âcart entre la valeur observ√©e et estim√©e pour x = 21 : {ecart} (L'√©cart est appel√© r√©sidu)")

```

*`L‚Äô√©cart (ou r√©sidu)` est correctement calcul√© comme la diff√©rence entre la valeur observ√©e et la valeur pr√©dite.*

# *3.8 V√©rification du passage par le point moyen t (x¬Ø, y¬Ø)*

*-Discussion sur la g√©n√©ralisation du passage par le point moyen pour toute droite de r√©gression*

```{python}
# Calculer les moyennes de x et y
x_bar = donnees['x'].mean()
y_bar = donnees['y'].mean()

# V√©rifier si la droite passe par (xÃÑ, yÃÑ)
y_estime_bar = slope * x_bar + intercept
passe_par_moyen = np.isclose(y_estime_bar, y_bar)
print(f"Point moyen (xÃÑ, »≥) : ({x_bar}, {y_bar})")
print(f"La droite passe-t-elle par (xÃÑ, »≥) ? : {passe_par_moyen}")

```

*Cette v√©rification est importante pour confirmer que la droite de r√©gression passe bien par le barycentre (x¬Ø, y¬Ø), ce qui est une propri√©t√© fondamentale des moindres carr√©s.*

# ***Exercice 4 : Donn√©es COVID-19 S√©n√©gal***

# *4.1 Lecture et nettoyage des donn√©es*

*-Lecture du fichier regions_cas.csv*

```{python}
import pandas as pd

# Charger un fichier Excel
dataframe = pd.read_excel("regions_cas.xlsx")  # Utilise la bonne fonction pour les fichiers Excel

# Afficher un aper√ßu des donn√©es
print(dataframe)

```

*-Nettoyage des noms de r√©gions et mettre la premi√®re lettre en majuscule*

```{python}
# Nettoyage des noms des colonnes en enlevant les accents et les points, et en mettant la premi√®re lettre en majuscule
dataframe.columns = [unidecode(col).replace('.', '').title() for col in dataframe.columns]

# Affichage des noms des colonnes apr√®s nettoyage
print("Les noms des colonnes apr√®s nettoyage :")
print(dataframe.columns)

# R√©organisation des donn√©es pour avoir une colonne "Date", une colonne "Region" et une colonne "Malades"
donn√©es_transform√©es = pd.melt(dataframe, id_vars=["Date"], var_name="Region", value_name="Malades")

# Affichage des donn√©es apr√®s la transformation
print("Les donn√©es transform√©es :")
print(donn√©es_transform√©es)

# Sauvegarder les donn√©es dans un fichier CSV
donn√©es_transform√©es.to_csv("covid_data.csv", index=False)

# Afficher le contenu du fichier CSV
print(pd.read_csv("covid_data.csv"))
print(tab)
```

# *4.2 Conversion de la variable date en type datetime et suppression de toutes les lignes ayant des valeurs manquantes (s‚Äôil en existe)*

*- Conversion de la variable date en type datetime*

```{python}
#Convertir la variable date en datetime
#Utilisons la fonction pd.to_datetime pour convertir la date
donn√©es_transform√©es['Date'] = pd.to_datetime(donn√©es_transform√©es['Date'], errors='coerce')  # Utilisation de 'coerce' pour g√©rer les erreurs
print(donn√©es_transform√©es)
```

*- Supprimer toutes les lignes ayant des valeurs manquantes (s‚Äôil en existe)*

```{python}
#Utilisons la m√©thode `dropna` pour supprimer les lignes qui ont des valeurs manquantes
donn√©es_transform√©es = donn√©es_transform√©es.dropna()
print(donn√©es_transform√©es)
```

# *4.3 Cr√©ation d'une fonction qui retourne un dataframe √† 3 colonnes (date, region, maladesparegion). La derni√®re colonne contiendra le nombre de malades de covid-19 par r√©gions aux diff√©rentes dates donn√©es.*

```{python}
import pandas as pd
import unidecode
#Cr√©ons une fonction qui retourne un dataframe √† trois colonnes date,region et maladesparregion:

def transformation(donn√©es_transform√©es):

    # Utilisation de melt pour transformer les r√©gions en ligne
    donn√©es_transform√©es = pd.melt(dataframe, id_vars=["Date"], var_name="Region", value_name="maladesparregion")
    
    return donn√©es_transform√©es


donn√©es_nouvelles = transformation(donn√©es_transform√©es)  
print(donn√©es_nouvelles)
```

# *4.4 Estimer de Œª*

```{python}
#Calculons la moyenne de la colonne maladesparregion:
moy = donn√©es_nouvelles['maladesparregion'].mean()
print( "Œª =",moy)
```

# *4.5 Utilisation d'un test statistique pour v√©rifier si la variable maladesparegion suit une loi de Poisson*

```{python}
import numpy as np
import scipy.stats as stats

# Estimation du param√®tre Œª √† partir de la moyenne des donn√©es
moy = donn√©es_nouvelles['maladesparregion'].mean()
estimation = moy  # Œª est estim√© par la moyenne des malades

# D√©finir le nombre de classes (bins) pour l'histogramme
nbre_classe = np.arange(donn√©es_nouvelles['maladesparregion'].min(), donn√©es_nouvelles['maladesparregion'].max() + 1)

# Calcul des fr√©quences observ√©es dans les diff√©rentes classes
observed_frequencies, bin_edges = np.histogram(donn√©es_nouvelles['maladesparregion'], bins=nbre_classe)

# Calcul des fr√©quences th√©oriques attendues pour chaque bin sous l'hypoth√®se de Poisson
expected_frequencies = []
for i in range(len(nbre_classe) - 1):
    # Calcul de la probabilit√© d'avoir un nombre de malades dans chaque intervalle
    prob_range = stats.poisson.cdf(nbre_classe[i+1], estimation) - stats.poisson.cdf(nbre_classe[i], estimation)
    expected_frequencies.append(prob_range)

# Normalisation pour avoir la m√™me taille que les fr√©quences observ√©es
expected_frequencies = np.array(expected_frequencies) * len(donn√©es_nouvelles)

# Ajouter une petite constante pour √©viter les z√©ros dans les fr√©quences attendues
# Cela permet d'√©viter la division par z√©ro ou les erreurs dans le test du chi carr√©
expected_frequencies = np.maximum(expected_frequencies, 1e-10)

# Effectuer le test du chi carr√©
chi2_stat, p_value = stats.chisquare(observed_frequencies, expected_frequencies)

# Afficher les r√©sultats
print(f"Statistique du test chi carr√© : {chi2_stat}")
print(f"Valeur p du test : {p_value}")

# Interpr√©ter le r√©sultat
if p_value < 0.05:
    print("Nous rejetons l'hypoth√®se nulle : les donn√©es ne suivent pas une loi de Poisson.")
else:
    print("Nous ne rejetons pas l'hypoth√®se nulle : les donn√©es suivent probablement une loi de Poisson.")


```

# *4.6 Estimation de r et de p*

```{python}
import numpy as np

# Calcul de la moyenne et de la variance des donn√©es
moy = donn√©es_nouvelles['maladesparregion'].mean()
var = donn√©es_nouvelles['maladesparregion'].var()

# Estimation de p et r
p = moy / var
r = moy* p / (1 - p)

print(f"Estimation du param√®tre p : {p}")
print(f"Estimation du param√®tre r : {r}")
```

# *4.6 Cr√©stion de la fonction CarteRegions(madate) qui affiche la carte choropl√®the des r√©gions en utilisant le nombre de malades*

*Installons les bibliotheques geopandas*

```{python}
import geopandas as gpd
import pandas as pd
import matplotlib.pyplot as plt

def CarteRegions(madate, geojson_file="gadm41_SEN_1.json", data_file="covid_data.csv"):
    
    # Charger les donn√©es g√©ographiques
    geo_data = gpd.read_file(geojson_file)

    # Charger les donn√©es des malades
    data = pd.read_csv(data_file)

    # Filtrer les donn√©es pour la date donn√©e
    data_date = data[data["Date"] == madate]


    # V√©rifier si des donn√©es existent pour la date donn√©e
    if data_date.empty:
        print(f"Aucune donn√©e disponible pour la date : {madate}")
        return

    # Normaliser les noms des r√©gions
    geo_data["Region"] = geo_data["NAME_1"].str.strip().str.title()
    data_date.loc[:, "Region"] = data_date["Region"].str.strip().str.title()
    # Fusionner les donn√©es g√©ographiques avec les donn√©es des malades
    geo_merged = geo_data.merge(data_date, on="Region", how="left")

    # Cr√©er une figure pour la carte
    fig, ax = plt.subplots(1, 1, figsize=(12, 10))

    # Tracer la carte avec les donn√©es des malades
    geo_merged.plot(
        column="Malades",
        cmap="YlOrRd",
        linewidth=0.8,
        ax=ax,
        edgecolor="black",
        legend=True,
        legend_kwds={"label": "Nombre de malades par r√©gion", "orientation": "horizontal"}
    )

    # Ajouter les noms des r√©gions
    for _, row in geo_merged.iterrows():
        if not pd.isna(row["Malades"]):  # V√©rifier qu'il y a des donn√©es
            x, y = row["geometry"].centroid.x, row["geometry"].centroid.y
            ax.annotate(
                text=row["Region"],
                xy=(x, y),
                horizontalalignment="center",
                fontsize=9,
                color="black"
            )

    # Ajouter un titre
    ax.set_title(f"Carte des malades de COVID-19 au S√©n√©gal pour la date : {madate}", fontsize=15)

    # Supprimer les axes
    ax.axis("off")

    # Afficher la carte
    plt.show()

# Exemple d'appel de la fonction
CarteRegions("2020-08-31")


```
